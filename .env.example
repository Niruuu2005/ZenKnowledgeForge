# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_KEEP_ALIVE=0

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=zenknowledge123

# ComfyUI Configuration (optional - for image generation)
COMFYUI_URL=http://localhost:8188

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma

# Session Storage
SESSION_DB_PATH=./data/sessions.db

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/zenknowledgeforge.log

# Hardware Constraints
MAX_VRAM_MB=5500
MAX_CONCURRENT_MODELS=1

# SINGLE MODEL MODE - Use ONE model for ALL agents (NO swapping, much faster!)
# Uncomment to enable. Recommended models: qwen2.5:7b-instruct-q4_K_M, llama3.1:8b-instruct-q4_K_M
# SINGLE_MODEL=qwen2.5:7b-instruct-q4_K_M
# SINGLE_MODEL_VRAM=5000

# Performance Settings
MAX_CONCURRENT_BROWSER_TABS=5
RESEARCH_TIMEOUT_SECONDS=60
EMBEDDING_BATCH_SIZE=32

# Output Settings
DEFAULT_OUTPUT_DIR=./outputs
DEFAULT_MODE=research
